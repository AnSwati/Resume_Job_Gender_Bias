import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Ensure cv_df is not empty
if len(cv_df) == 0:
    raise ValueError("cv_df is empty. Check preceding operations.")

# Stratified split by occupation
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.35, random_state=42)
train_index, temp_index = next(sss.split(cv_df, cv_df['Occupation']))
train_df = cv_df.iloc[train_index]
temp_df = cv_df.iloc[temp_index]

# Further split temp_df into test and validation sets (25% test, 10% validation of the original data)
sss_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.7143, random_state=42)  # 0.7143 of temp_df gives 25% of the original data for test
test_index, val_index = next(sss_temp.split(temp_df, temp_df['Occupation']))
test_df = temp_df.iloc[test_index]
val_df = temp_df.iloc[val_index]

# Tokenizer setup
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_df['CV'])

# Tokenize and pad sequences
X_train_seq = tokenizer.texts_to_sequences(train_df['CV'])
X_test_seq = tokenizer.texts_to_sequences(test_df['CV'])
X_val_seq = tokenizer.texts_to_sequences(val_df['CV'])

# Check if any sequences are empty after tokenization
if not X_train_seq or not any(len(seq) > 0 for seq in X_train_seq):
    raise ValueError("All sequences are empty. Check the tokenizer's vocabulary and the texts.")

# Since we have valid sequences, proceed to pad them
X_train = pad_sequences(X_train_seq)
X_test = pad_sequences(X_test_seq, maxlen=X_train.shape[1])
X_val = pad_sequences(X_val_seq, maxlen=X_train.shape[1])

# Encode labels
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(train_df['Occupation'])
y_train = to_categorical(y_train)
y_test = label_encoder.transform(test_df['Occupation'])
y_test = to_categorical(y_test)
y_val = label_encoder.transform(val_df['Occupation'])
y_val = to_categorical(y_val)

# Initialize a dictionary to store GloVe embeddings
glove_embeddings = {}
with open('glove.txt', 'r', encoding='utf8') as file:
    for line in file:
        parts = line.split()
        word = parts[0]
        vector = np.asarray(parts[1:], dtype='float32')
        glove_embeddings[word] = vector

# Prepare the embedding matrix
embedding_dim = 300  # Dimensionality of the GloVe embeddings you chose
vocab_size = len(tokenizer.word_index) + 1  # Adding 1 to account for padding token
embedding_matrix = np.zeros((vocab_size, embedding_dim))
for word, i in tokenizer.word_index.items():
    embedding_vector = glove_embeddings.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

# Calculate gender_weights
gender_weights = {category: {'Male': 0, 'Female': 0, 'count': 0} for category in train_df['Occupation'].unique()}
for _, row in train_df.iterrows():
    category = row['Occupation']
    gender = row['Gender']
    
    # Skip rows where 'category' or 'Gender' is NaN
    if pd.isna(category) or pd.isna(gender):
        continue
    
    gender_weights[category][gender] += 1
    gender_weights[category]['count'] += 1

for category in gender_weights:
    total = gender_weights[category]['count']
    for gender in ['Male', 'Female']:
        gender_count = gender_weights[category][gender]
        if gender_count > 0:
            gender_weights[category][gender] = total / gender_count

# Adjusted sample_weights calculation to handle NaN values
sample_weights = np.array([
    gender_weights.get(row['Occupation'], {'Male': 1, 'Female': 1}).get(row['Gender'], 1)
    for _, row in train_df.iterrows()
])

# Build and compile the model
model = Sequential([
    Embedding(input_dim=len(tokenizer.word_index) + 1,
              output_dim=embedding_dim,
              weights=[embedding_matrix],
              input_length=X_train.shape[1],
              trainable=False),  # Prevent the embeddings from being updated
    LSTM(128, dropout=0.2, recurrent_dropout=0.2),
    Dense(y_train.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with gender-weighted sampling
history = model.fit(X_train, y_train, sample_weight=sample_weights, epochs=10, validation_data=(X_val, y_val))

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

# Create a DataFrame for test data and predictions
test_results_df = test_df.copy()
test_results_df['y_true'] = y_test_classes
test_results_df['y_pred'] = y_pred_classes
test_results_df['Gender'] = test_df['Gender']

# Initialize lists to store results
results = []

# Get unique occupations
occupations = label_encoder.classes_

# Calculate metrics for each occupation
for i, occupation in enumerate(occupations):
    # Filter data for current occupation
    occ_df = test_results_df[test_results_df['y_true'] == i]
    
    if len(occ_df) == 0:
        continue
    
    # Calculate accuracy
    acc = accuracy_score(occ_df['y_true'], occ_df['y_pred'])
    
    # Calculate TPR and Precision for males and females
    tpr_m = recall_score(occ_df[occ_df['Gender'] == 'Male']['y_true'], occ_df[occ_df['Gender'] == 'Male']['y_pred'], average='binary', pos_label=i)
    tpr_f = recall_score(occ_df[occ_df['Gender'] == 'Female']['y_true'], occ_df[occ_df['Gender'] == 'Female']['y_pred'], average='binary', pos_label=i)
    prec_m = precision_score(occ_df[occ_df['Gender'] == 'Male']['y_true'], occ_df[occ_df['Gender'] == 'Male']['y_pred'], average='binary', pos_label=i)
    prec_f = precision_score(occ_df[occ_df['Gender'] == 'Female']['y_true'], occ_df[occ_df['Gender'] == 'Female']['y_pred'], average='binary', pos_label=i)
    
    # Calculate TPR Gap and Precision Gap
    tpr_gap = abs(tpr_m - tpr_f)
    prec_gap = abs(prec_m - prec_f)
    
    # Append results to list
    results.append([occupation, acc, tpr_m, tpr_f, prec_m, prec_f, tpr_gap, prec_gap])

# Convert results to DataFrame for display
results_df = pd.DataFrame(results, columns=['Occupation', 'Acc.', 'TPR (M)', 'TPR (F)', 'Prec. (M)', 'Prec. (F)', 'TPR Gap', 'Prec. Gap'])

import ace_tools as tools; tools.display_dataframe_to_user(name="Occupation Metrics", dataframe=results_df)
