import pandas as pd
import numpy as np
import re
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate
from sklearn.metrics import accuracy_score, recall_score

# Load the dataset
cv_df = pd.read_csv('linkedin.csv')

# Function to clean 'Skills' column by removing numbered lists
def clean_skills(skills):
    return re.sub(r'\d+\.\s*', '', skills)

# Apply the function to the 'Skills' column
cv_df['Skills'] = cv_df['Skills'].apply(clean_skills)

# Combine 'Skills' and 'Description' into 'CV'
cv_df['CV'] = cv_df['Description'].astype(str) + ' ' + cv_df['Skills'].astype(str)

# Drop 'Description' and 'Skills' columns
cv_df.drop(columns=['Description', 'Skills'], inplace=True)

# Ensure cv_df is not empty
if len(cv_df) == 0:
    raise ValueError("cv_df is empty. Check preceding operations.")

# Stratified split by occupation
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.35, random_state=42)
train_index, temp_index = next(sss.split(cv_df, cv_df['Occupation']))
train_df = cv_df.iloc[train_index]
temp_df = cv_df.iloc[temp_index]

# Further split temp_df into test and validation sets
sss_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.7143, random_state=42)
test_index, val_index = next(sss_temp.split(temp_df, temp_df['Occupation']))
test_df = temp_df.iloc[test_index]
val_df = temp_df.iloc[val_index]

# Tokenizer setup
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_df['CV'])

# Tokenize and pad sequences
X_train_seq = tokenizer.texts_to_sequences(train_df['CV'])
X_test_seq = tokenizer.texts_to_sequences(test_df['CV'])
X_val_seq = tokenizer.texts_to_sequences(val_df['CV'])

# Check if any sequences are empty after tokenization
if not X_train_seq or not any(len(seq) > 0 for seq in X_train_seq):
    raise ValueError("All sequences are empty. Check the tokenizer's vocabulary and the texts.")

# Pad sequences
X_train = pad_sequences(X_train_seq)
X_test = pad_sequences(X_test_seq, maxlen=X_train.shape[1])
X_val = pad_sequences(X_val_seq, maxlen=X_train.shape[1])

# Encode gender
gender_encoder = LabelEncoder()
X_train_gender = gender_encoder.fit_transform(train_df['Gender'])
X_test_gender = gender_encoder.transform(test_df['Gender'])
X_val_gender = gender_encoder.transform(val_df['Gender'])

# Encode labels
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(train_df['Occupation'])
y_train = to_categorical(y_train)
y_test = label_encoder.transform(test_df['Occupation'])
y_test = to_categorical(y_test)
y_val = label_encoder.transform(val_df['Occupation'])
y_val = to_categorical(y_val)

# Initialize a dictionary to store GloVe embeddings
glove_embeddings = {}
with open('path_to_your_glove.txt', 'r', encoding='utf8') as file:  # Replace with the correct path
    for line in file:
        parts = line.split()
        word = parts[0]
        vector = np.asarray(parts[1:], dtype='float32')
        glove_embeddings[word] = vector

# Prepare the embedding matrix
embedding_dim = 300  # Dimensionality of the GloVe embeddings
vocab_size = len(tokenizer.word_index) + 1
embedding_matrix = np.zeros((vocab_size, embedding_dim))
for word, i in tokenizer.word_index.items():
    embedding_vector = glove_embeddings.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

# Calculate gender_weights
gender_weights = {category: {'Male': 0, 'Female': 0, 'count': 0} for category in train_df['Occupation'].unique()}
for _, row in train_df.iterrows():
    category = row['Occupation']
    gender = row['Gender']
    
    if pd.isna(category) or pd.isna(gender):
        continue
    
    gender_weights[category][gender] += 1
    gender_weights[category]['count'] += 1

for category in gender_weights:
    total = gender_weights[category]['count']
    for gender in ['Male', 'Female']:
        gender_count = gender_weights[category][gender]
        if gender_count > 0:
            gender_weights[category][gender] = total / gender_count

# Adjusted sample_weights calculation
sample_weights = np.array([
    gender_weights.get(row['Occupation'], {'Male': 1, 'Female': 1}).get(row['Gender'], 1)
    for _, row in train_df.iterrows()
])

# Build and compile the model
text_input = Input(shape=(X_train.shape[1],))
gender_input = Input(shape=(1,))

embedding = Embedding(input_dim=len(tokenizer.word_index) + 1,
                      output_dim=embedding_dim,
                      weights=[embedding_matrix],
                      input_length=X_train.shape[1],
                      trainable=False)(text_input)

lstm_out = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embedding)

# Concatenate LSTM output with gender input
merged = Concatenate()([lstm_out, gender_input])

dense = Dense(64, activation='relu')(merged)
output = Dense(y_train.shape[1], activation='softmax')(dense)

model = Model(inputs=[text_input, gender_input], outputs=output)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with gender-weighted sampling
history = model.fit([X_train, X_train_gender], y_train, 
                    sample_weight=sample_weights, 
                    epochs=10, 
                    validation_data=([X_val, X_val_gender], y_val))

# Make predictions on the test set
y_pred = model.predict([X_test, X_test_gender])
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

# Create a DataFrame for test data and predictions
test_results_df = test_df.copy()
test_results_df['y_true'] = y_test_classes
test_results_df['y_pred'] = y_pred_classes

# Initialize lists to store results
results = []

# Get unique occupations
occupations = label_encoder.classes_

# Calculate metrics for each occupation
for i, occupation in enumerate(occupations):
    # Filter data for current occupation
    occ_df = test_results_df[test_results_df['y_true'] == i]
    
    if len(occ_df) == 0:
        continue
    
    # Calculate accuracy
    acc = accuracy_score(occ_df['y_true'], occ_df['y_pred'])
    
    # Calculate TPR for males and females
    tpr_m = recall_score(occ_df[occ_df['Gender'] == 'Male']['y_true'], occ_df[occ_df['Gender'] == 'Male']['y_pred'], average='macro')
    tpr_f = recall_score(occ_df[occ_df['Gender'] == 'Female']['y_true'], occ_df[occ_df['Gender'] == 'Female']['y_pred'], average='macro')
    
    # Calculate TPR Gap
    tpr_gap = abs(tpr_m - tpr_f)
    
    # Append results to list
    results.append([occupation, acc, tpr_m, tpr_f, tpr_gap])

# Convert results to DataFrame for display
results_df = pd.DataFrame(results, columns=['Occupation', 'Acc.', 'TPR (M)', 'TPR (F)', 'TPR Gap'])

# Display the results
print(results_df)
